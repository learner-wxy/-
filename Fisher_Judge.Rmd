---
title: "Fisher线性判别函数"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Fisher线性判别函数，基本思想是投影，将k组p维数据投影到某一个方向  ，使得组之间尽可能分开,同一类的样本被投影后尽量扎堆，解决的是线性可分的,费希尔判别受量纲和数量级的影响
library(tidyverse)
library(foreign)
library(MASS)
```

```{r}
mydata<-read.spss("./例3-5.sav")
data<-as.data.frame(mydata)
data
```

# 两个类别数据，两个待判样本
```{r}
df <- data %>% 
  mutate(number = 1:31)%>% #编个号，方便选
  dplyr::select(number,everything())
donnot_konow <- df %>%
  filter( number %in% c(19,26)) #广东、西藏为待判样品
donnot_konow
first <- df %>%
  filter(number %in% c(1,9)) #北京、上海归为一类
first
second <- df %>%
  filter( !number %in% c(1,9,19,26)) #其余地区为一类
second
```




# 用包来实现类别的判断与分类
```{r}
df <- data %>% 
  mutate(number = 1:31)%>% #编个号，方便选
  dplyr::select(number,everything())
donnot_konow <- df %>%
  filter( number %in% c(19,26)) #广东、西藏为待判样品
donnot_konow
first <- df %>%
  filter(number %in% c(1,9)) %>% 
  mutate(genre = 1) %>% #北京上海为1类，顺便这一类的全部标记个1，这个包应该算这个为先验信息，不然没法做
  dplyr::select(genre,number,everything())
first
second <- df %>%
  filter( !number %in% c(1,9,19,26)) %>% 
  mutate(genre = 2) %>% #除广东、西藏、北京上海为2类，并且全部标记个2
  dplyr::select(genre,number,everything())
second

train_sample <- first %>% #把除了广东与西藏的其余城市合并，开始造作了
  rbind(second)
train_sample

fisher_model <- lda(genre ~ x1+x2+x3+x4+x5+x6+x7+x8, data=train_sample)#genre为分类标识，其余为八个指标，这里貌似后面全是判别指标的话，可以用点来代替。
fisher_model# 判别函数为 0.0006388214*x1 + 0.0013250299*x2 -0.0015453976*x3  -0.0019589553*x4 +0.0014962902*x5 -0.0003410774*x6  -0.0011726981*x7 -0.0020388069*x8
        #29个城市得分依次为-10.98538469  -12.51078456 -0.55739557 -0.48343902  0.23097937 1.52871713 0.26389623  0.76463092  1.32363596  -0.89682690  0.10345994 1.97870916  -0.82392271  1.54772684  0.33221626 -0.35585638 0.39229619  1.34066979  1.14658710  2.63960296 1.64459206  2.23417796   1.89448886 0.99538672 -0.01681659 0.99533667 1.63125178 2.05245883 1.58960569

self_predict <-  predict(fisher_model)#用这个预测下本来就已经分类的呢，来比较下有没有错，嗯结果是一样的
cbind(train_sample$genre,self_predict$x,self_predict$class)#第一列为本来的类别，第二列为得分把，第三列为用MASS包计算来的类别
table(train_sample$genre,self_predict$class)#生成实际与预判的交叉表，发现没有判别错误的

P <- predict(fisher_model, donnot_konow)#预测广东与西藏
cbind(P$x,P$class)#广东与西藏得分为-0.03072896、4.75081654，    看到都被分到了第二类
sum(diag(table(train_sample$genre,self_predict$class)))/sum(table(train_sample$genre,self_predict$class))#生成预判精度，diag是取对角线的元素，就是判别得和原来的相除
```



